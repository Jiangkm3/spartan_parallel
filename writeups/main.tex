\documentclass{article}
\usepackage[letterpaper, total={6in, 8in}]{geometry}
\usepackage{xcolor}
\usepackage{amsfonts}

\newcommand{\red}[1] {\color{red}#1\color{black}}
\newcommand{\code}{\texttt}
\newcommand{\Qsum}{Q_{\mathtt{sum}}}
\newcommand{\Qmax}{Q_{\mathtt{max}}}
\newcommand{\qmax}{q_{\mathtt{max}}}
\renewcommand{\P}{\mathcal{P}}
\newcommand{\V}{\mathcal{V}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\eq}{\widetilde{\mbox{eq}}}
\newcommand{\valid}{\tilde{\mbox{valid}}}
\newcommand{\io}{\widetilde{(\mbox{io, 1})}}

\title{Spartan Parallel}
\author{Kunming Jiang}
\date{Sep 21, 2023}

\begin{document}

\maketitle

\section{Introduction}\label{intro}

This document serves as a record for bookkeeping for the implementation of \code{spartan\_parallel}. As a result, its contents stand closer to the Rust code of the repository than to the theory discussed in Srinath's paper.

The original Spartan handles the R1CS problem, which is consisted of three matrices $A, B, C$ of size $X \times Y$ and a length-$Y$ variable (inputs + witnesses) vector $z$. The goal is to prove $Az\cdot Bz = Cz$.

The data-parallel version of the problem is consisted of $P$ R1CS instances of the form $\{A_i, B_i, C_i\}$, where each $A_i, B_i, C_i$ are $X \times Y$ matrices, $X$ represents the number of constraints and $Y$ represents the number of variables (inputs + witnesses). For each instance $\{A_i, B_i, C_i\}$, there are $Q_i$ (input, witnesses) vectors of length $Y$ that claim to be a correct execution of the instance. We call such vector a \textbf{proof}, denoted as $z_{i, 0},\dots z_{i, Q_i}$. The goal is to prove and verify all proofs and all instances using SNARK: specifically, a modified version of Spartan that can handle data-parallelism.

For simplicity, Spartan makes the following assumption:
\begin{enumerate}
    \item All matrices $A_i, B_i, C_i$ are square matrices. This means that for every instance, $X = Y$. However, we can relax this assumption to $X = O(Y)$. \label{ass:square}

    \item The number of inputs / outputs in any proof is exactly one less than the number of witnesses (we can always set unused inputs to be 0). This means that any $z$ vector can be separated into two halves, where the first half contains the inputs / outputs plus the constant 1, and the second half contains all the witnesses. \label{ass:num_of_inputs}
    
    \emph{One can see that such setup leads to inefficiencies. This is especially wasteful in our context, as one will see later.}

    \item Number of constraints and variables ($X$ and $Y$) are all powers of 2. Again, one can always append dummies. \label{ass:x_y_pow2}
\end{enumerate}

\noindent We add to the list our own set of assumptions:
\begin{enumerate}
    \setcounter{enumi}{4}
    \item Number of instances and proofs ($P$ and $Q_i$) are also powers of 2. Note that values of $Q_i$'s can differ, but all of them must be powers of 2. \label{ass:p_q_pow2}
    \item Number of proofs for each instance is in decreasing order, i.e. $\forall i\in [1, P), Q_i \geq Q_{i+1}$. \label{ass:q_decreasing}
\end{enumerate}

Define $\Qmax \leftarrow \max_i Q_i$ and $\Qsum \leftarrow \sum_i Q_i$. We assume $\Qsum = O(\log (P \cdot \Qmax))$. Let $p = \log P$, $q_i = \log Q_i$, $\qmax = \log \Qmax$, $x = \log X$, and $y = \log Y$. We want the total runtime of the Prover ($\P$) to be $O(\Qsum \cdot X)$, and that of the Verifier ($\V$) to be $O(\log(P \cdot \Qmax \cdot Y))$.

\section{Spartan as a Non-Interactive Argument System}\label{spartan}
In contrast to how Spartan is presented in the paper, we here illustrate the Spartan procedure as a SNARK to stick closer to the code. In the following sections, the Prover ($\P$) is the party that produces the proof (which simulates both the prover $\P_i$ and the verifier $\V_i$ of the interactive proof) and the Verifier ($\V$) is the party verifying that proof. Furthermore, unless specified otherwise, all "polynomials" in the document refers to multilinear polynomials, and are represented as evaluations on a boolean hypercube of all variables. The \textbf{dense} format represents a polynomial of $n$ variables as a length-$2^n$ vector which include every point on the boolean hypercube, while the \textbf{sparse} format only records down the non-zero entries and their indexes. Polynomials are represented in dense form by default.

Spartan as a SNARK can be divided into three stages, each with several steps:
\subsection{Stage 1: Commitment}
This is the one-time setup of stage Spartan with only one step:
\begin{enumerate}
    \item A third (\red{trusted?}) party converts the matrices $A, B, C$ to multilinear polynomials in sparse format. It then commits these polynomials.
\end{enumerate}

\subsection{Stage 2: Proof Generation}
In this stage, a prover $\P$ is given the instances and the variable list, and needs to generate a proof that the inputs and witnesses satisfy the constraints. It does so by simulating an interactive between a prover $\P_i$ and verifier $\V_i$, and needs to perform the following steps:
\begin{enumerate}
    \setcounter{enumi}{1}
    \item $\P$ converts the witnesses into a multilinear polynomial $w(y)$ in dense form and commits.
    \item $\P$ converts $z$ into a multilinear polynomial in dense form.
    \item $\P$ simulates $\V_i$ and produces a length-$x$ random vector $\tau$. It computes the polynomial $\eq_\tau(x)$ in dense form.
    \item $\P$ computes polynomials $Az(x)$, $Bz(x)$, $Cz(x)$ and express them in dense format.
    \item $\P$ simulates sum-check 1 between $\P_i$ and $\V_i$. The goal is to prove
    $$\displaystyle0 =\sum_x \eq_\tau(x)\cdot (Az(x)\cdot Bz(x) - Cz(x))$$
    At the end of the sum-check, $\P$ obtains a length-$x$ random vector $r_x$, as well as $Az(r_x)$, $Bz(r_x)$, $Cz(r_x)$, $\eq_\tau(r_x)$, and
    $$e_x = \eq_\tau(r_x)\cdot (Az(r_x)\cdot Bz(r_x) - Cz(r_x))$$
    \item $\P$ generates a proof that $e_x$ is indeed $\eq_\tau(r_x)\cdot (Az(r_x)\cdot Bz(r_x) - Cz(r_x))$, in zero-knowledge if necessary.\label{step_spartan:p_proof_1}
    \item $\P$ simulates $\V_i$ and produces 3 random values $r_A$, $r_B$, and $r_C$, and computes 
    $$T = r_A\cdot Az(r_x) + r_B\cdot Bz(r_x) + r_C\cdot Cz(r_x)$$
    \item $\P$ computes polynomial $ABC(y)$ in dense form, defined as
    $$ABC(y) = r_A\cdot A(r_x, y) + r_B\cdot B(r_x, y) + r_C\cdot C(r_x, y)$$
    \item $\P$ also converts $z$ into a polynomial $Z(y)$ in dense form.
    \item $\P$ simulates sum-check 2 between $\P_i$ and $\V_i$. The goal is to prove
    $$\displaystyle T = \sum_y ABC(y)\cdot Z(y)$$
    At the end of the sum-check, $\P$ obtains a length-$y$ random vector $r_y$, as well as $ABC(r_y)$, $Z(r_y)$, and
    $$e_y = ABC(r_y)\cdot Z(r_y)$$
    \emph{Note: As stated by assumption \ref{ass:num_of_inputs}, the first half of $Z$ are inputs and the second half of $Z$ are witnesses, so $Z(r_y) = (1 - r_y[0])\cdot w(r_y[1..]) + r_y[0]\cdot \io(r_y[1..])$}
    \item $\P$ computes $w_{r_y} = w(r_y[1..])$ and produces a proof of the computation, presumably in zero-knowledge.\label{step_spartan:p_proof_2}
    \item $\P$ generates a proof that $e_y$ is indeed $ABC(r_y)\cdot Z(r_y)$, presumably in zero-knowledge.\label{step_spartan:p_proof_3}
\end{enumerate}
Finally, $\P$ reveals the commitment for $w$, $e_x$, $e_y$, $w_{r_y}$, as well as proofs in step \ref{step_spartan:p_proof_1}, \ref{step_spartan:p_proof_2}, and \ref{step_spartan:p_proof_3}.

\subsection{Stage 3: Proof Verification}
In this stage, a verifier $\V$ wants to verify the correctness of the proof generated by $\P$, which is consisted of the following steps:
\begin{enumerate}
    \setcounter{enumi}{13}
    \item $\V$ follows $\P$'s transcript and reproduces the length-$x$ random vector $\tau$.
    \item $\V$ verifies the correctness of the procedure for sumcheck 1. During the verification, $\V$ reproduces $r_x$.
    \item $\V$ computes $\eq_\tau(r_x)$ and verifies $e_x = \eq_\tau(r_x)\cdot (Az(r_x)\cdot Bz(r_x) - Cz(r_x))$, potentially in zero-knowledge.
    \item $\V$ reproduces $r_A$, $r_B$, $r_C$ and verifies the correctness of the procedure for sumcheck 2. During the verification, $\V$ reproduces $r_y$.
    \item $\V$ verifies $w_{r_y} = w(r_y)$ (in zero-knowledge).\label{step_spartan:w-verification}
    \item $\V$ converts the input into a multilinear polynomial $\io$ in sparse form and evaluates it on $r_y[1..]$.\label{step_spartan:io-compute}
    \item $\V$ uses $w_{r_y}$ and $\io(r_y[1..])$ to compute $Z(r_y)$, which is then used to verify the correctness of $e_y$.
\end{enumerate}

Note that verifications of sum-checks and computations take $O(\log X)$ time (assume $X\approx Y$). Thus, runtime of $\V$ largely depends on time to open commitment for $w$ (step \ref{step_spartan:w-verification}) and the number of non-zero inputs (step \ref{step_spartan:io-compute}). When implementing data-parallelism to Spartan, these two factors become crucial.


\section{Implement Spartan Using Data-Parallelism}\label{spartan_parallel}

We begin by modifying Spartan to support data-parallelism. The data-paralleled version very much resembles the original Spartan. We first present a naive implementation, then reason about how to improve the time and space compexity.

The naive \code{spartan\_parallel} protocol is shown below, again in three stages.
\subsection{Stage 1: Commitment}\label{stage:commitment}
This is the one-time setup of stage Spartan with only one step:
\begin{enumerate}
    \item A third (\red{trusted?}) party converts the matrices $A_i, B_i, C_i$ to $P\times \Qmax \times X\times Y$ multilinear polynomials in sparse format. It then commits these polynomials.
\end{enumerate}

\subsection{Stage 2: Proof Generation}\label{stage:prover}
In this stage, a prover $\P$ is given the instances and the variable list, and needs to generate a proof that the inputs and witnesses satisfy the constraints. It does so by simulating an interactive between a prover $\P_i$ and verifier $\V_i$, and needs to perform the following steps:
\begin{enumerate}
    \setcounter{enumi}{1}
    \item $\P$ converts the witnesses into a multilinear polynomial $w(p, q, y)$ in dense form and commits.
    \item $\P$ converts $z_i$ into a multilinear polynomial $Z(p, q, y)$ in dense form.
    \item $\P$ simulates $\V_i$ and produces a length-$(p + q + x)$ random vector $\tau$. It computes the polynomial $\eq_{\tau}(p, q, x)$ in dense form.
    \item $\P$ computes polynomials $Az(p, q, x)$, $Bz(p, q, x)$, $Cz(p, q, x)$ and express them in dense format.
    \item $\P$ simulates sum-check 1 between $\P_i$ and $\V_i$. The goal is to prove
    $$\displaystyle0 =\sum_{p, q, x} \eq_\tau(p, q, x)\cdot (Az(p, q, x)\cdot Bz(p, q, x) - Cz(p, q, x))$$
    At the end of the sum-check, $\P$ obtains a length-$(p + q + x)$ random vector $(r_p, r_q, r_x)$, as well as $Az(r_p, r_q, r_x)$, $Bz(r_p, r_q, r_x)$, $Cz(r_p, r_q, r_x)$, $\eq_\tau(r_p, r_q, r_x)$, and
    $$e_x = \eq_\tau(r_p, r_q, r_x)\cdot (Az(r_p, r_q, r_x)\cdot Bz(r_p, r_q, r_x) - Cz(r_p, r_q, r_x))$$
    \item $\P$ generates a proof that $e_x$ is indeed $\eq_\tau(r_p, r_q, r_x)\cdot (Az(r_p, r_q, r_x)\cdot Bz(r_p, r_q, r_x) - Cz(r_p, r_q, r_x))$, in zero-knowledge if necessary.\label{step:p_proof_1}
    \item $\P$ simulates $\V_i$ and produces 3 random values $r_A$, $r_B$, and $r_C$, and computes 
    $$T = r_A\cdot Az(r_p, r_q, r_x) + r_B\cdot Bz(r_p, r_q, r_x) + r_C\cdot Cz(r_p, r_q, r_x)$$
    \item $\P$ computes polynomial $ABC_{r_x}(p, y)$ in dense form, defined as
    $$ABC_{r_x}(p, y) = r_A\cdot A_{r_x}(p, y) + r_B\cdot B_{r_x}(p, y) + r_C\cdot C_{r_x}(p, y)$$
    \item $\P$ also converts $z$ into a polynomial $Z_{r_q}(p, y)$ in dense form.
    \item Note that $f(y) = ABC_{r_x}(r_p, y)\cdot z_{r_q}(r_p, y)$ is not a multilinear polynomial, since it is quadratic to $r_p$. Instead, $\P$ computes $\eq_{r_p}(p)$ in dense form.
    \item $\P$ simulates sum-check 2 between $\P_i$ and $\V_i$. The goal is to prove
    $$\displaystyle T = \sum_{p^*, y} ABC_{r_x}(p^*, y)\cdot Z_{r_q}(p^*, y) \cdot \eq_{r_p}(p^*)$$
    At the end of the sum-check, $\P$ obtains a length-($p + y$) random vector $(r_p^*, r_y)$, as well as $ABC_{r_x}(r_p^*, r_y)$, $Z_{r_q}(r_p^*, r_y)$, $\eq_{r_p}(r_p^*)$, and
    $$e_y = ABC_{r_x}(r_p^*, r_y)\cdot Z_{r_q}(r_p^*, r_y)\cdot \eq_{r_p}(r_p^*)$$
    \emph{Note: Similary, as stated by assumption \ref{ass:num_of_inputs}, the first half of $z_i$ are inputs and the second half of $z_i$ are witnesses, so $Z_{r_q}(r_p^*, r_y) = (1 - r_y[0])\cdot w_{r_q}(r_p^*, r_y[1..]) + r_y[0]\cdot \io_{r_q}(r_p^*, r_y[1..])$}
    \item $\P$ computes $w_{r_y} = w_{r_q}(r_p^*, r_y[1..])$ and produces a proof of the computation, presumably in zero-knowledge.\label{step:p_proof_2}
    \item $\P$ generates a proof that $e_y$ is indeed $ABC_{r_x}(r_p^*, r_y)\cdot Z_{r_q}(r_p^*, r_y)$, presumably in zero-knowledge.\label{step:p_proof_3}
\end{enumerate}
Finally, $\P$ reveals the commitment for $w$, $e_x$, $e_y$, $w_{r_y}$, as well as proofs in step \ref{step_spartan:p_proof_1}, \ref{step_spartan:p_proof_2}, and \ref{step_spartan:p_proof_3}.

\subsection{Stage 3: Proof Verification}\label{stage:verifier}
In this stage, a verifier $\V$ wants to verify the correctness of the proof generated by $\P$, which is consisted of the following steps:
\begin{enumerate}
    \setcounter{enumi}{13}
    \item $\V$ follows $\P$'s transcript and reproduces the length-($p + q + x$) random vector $\tau$.
    \item $\V$ verifies the correctness of the procedure for sumcheck 1. During the verification, $\V$ reproduces $r_p, r_q, r_x$.
    \item $\V$ computes $\eq_\tau(r_p, r_q, r_x)$ and verifies $e_x = \eq_\tau(r_p, r_q, r_x)\cdot (Az(r_p, r_q, r_x)\cdot Bz(r_p, r_q, r_x) - Cz(r_p, r_q, r_x))$, potentially in zero-knowledge.
    \item $\V$ reproduces $r_A$, $r_B$, $r_C$ and verifies the correctness of the procedure for sumcheck 2. During the verification, $\V$ reproduces $r_p^*, r_y$.
    \item $\V$ computes $\eq_{r_p}(r_p^*)$
    \item $\V$ verifies $w_{r_y} = w(r_p^*, r_q, r_y)$ (in zero-knowledge).\label{step:w-verification}
    \item $\V$ converts the input into a multilinear polynomial $\io$ in sparse form and evaluates it on $(r_p^*, r_q, r_y[1..])$.\label{step:io-compute}
    \item $\V$ uses $w_{r_y}$ and $\io(r_p^*, r_q, r_y[1..])$ to compute $Z_{r_q}(r_y)$, which is then used to verify the correctness of $e_y$.
\end{enumerate}

\section{Identifying Runtime Overhead}\label{identify}
\subsection{Verifier Cost}
Since we only require the Verifier cost to be $O(\log(P \cdot \Qmax \cdot Y))$. This has already been achieved by the above protocol, so there isn't any improvement we need to do. Here's the cost breakdown:
\begin{itemize}
    \item In step \ref{step:sample-tau}: $O(\log(P \cdot \Qmax \cdot Y))$ for sampling $\tau$.
    \item In step \ref{step:sumcheck-1}: $O(\log(P \cdot \Qmax \cdot Y))$ due to the sum-check having $p + \qmax + x$ rounds. Assume $X$ and $Y$ are of similar size.
    \item In step \ref{step:sumcheck-1-verify}: $O(\log(P \cdot \Qmax \cdot Y))$ for evaluating $\eq_\tau(r)$.
    \item In step \ref{step:sumcheck-2}: $O(\log(P \cdot Y))$ due to the sum-check having $p + y$ rounds.
    \item In step \ref{step:evaluate-input}: $O(\log(P \cdot \Qmax \cdot Y))$ for evaluating the input, and $O(\log(P))$ for evaluating $\eq_{r_p}(r_p^*)$.
\end{itemize}

\subsection{Prover Cost}
The prover's cost is currently $O(P\cdot\Qmax\cdot Y\cdot)$, and we need to reduce it to $O(\Qsum \cdot X)$. Here's all the steps that exceeds that complexity:
\begin{itemize}
    \item Step \ref{step:witness-commit}: witness commit
    \item Step \ref{step:mat-product}: producing $Az$, $Bz$, $Cz$, and $\eq_\tau$
    \item Step \ref{step:sumcheck-1}: sum-check 1
    \item Step \ref{step:compute-z-poly}: compute $Z_{r_q}$
\end{itemize}
We now discuss how to improve Prover's cost in these steps.

\section{Reducing Time Complexity}\label{reduce-time}
Here are the general ideas on how to improve time complexity:
\begin{itemize}
    \item We assume that filling an array / matrix with 0s does not take time. This assumption helps us reduce the time complexity of the following steps:
    \begin{itemize}
        \item Step \ref{step:witness-commit}: to perform witness commit, we need to express witnesses as a $\F^{p + \qmax + x}\to\F$ dense polynomial. By the assumption, we can initialize this matrix to 0, and then fill-in the non-zero elements. This reduces the polynomial construction cost to $O(\Qsum \cdot X)$, which satisfies the time complexity.
        \item Step \ref{step:mat-product}: Using the similar idea, we can also initialize $Az$, $Bz$, $Cz$ as zero-polynomials and then fill in their non-zero entries. This reduces their cost to $O(\Qsum \cdot X)$.
    \end{itemize}
    \item Next, sum-check protocols can be easily modified to "skip" the zero parts, if these zero parts are clustered together in the polynomial. As a result, assume that the polynomials has $O(\Qsum \cdot X)$ non-zero entries and the zeros are clustered (in our case, cluster means that for certain $p$ and $q$, the polynomial always evaluates to 0 regardless of the choices of $y$), we can reduce the time complexity of sumchecks. We already show that this is the case for $Az$, $Bz$, and $Cz$, so what remaining is to reason about $\eq$.
    \item While at the first glance it seems like one can treat $\eq$ just like every other polynomial: initialize with 0 and fill in non-zero parts. We call this modified version $\eq^*$. However, such modification would result in $\V$ unable to compute the binding in logarithmic time. Instead, we do the following:
    \begin{itemize}
        \item Let $\valid:\F^{p + \qmax}\to \{0, 1\}$ be multilinear extension of the indicator function that evaluates to 1 if $(p, q)$ is a valid instance-(input, witness) index pair, 0 otherwise.
        \item The verifier, however, still cannot evaluate $\valid$ in logarithmic time. This is because since we make no assumption on $Q_i$'s and how they relate to $P$, expressing $\valid$ would take at least $O(P)$ time.
        \item Thus, $\P$ needs to commit to $\valid$ at the beginning of the protocol. $\P$ can then use $\eq^*$ during sumcheck, and $\V$ use $\eq \cdot \valid$ to bind $\eq^*$ to $r_p$ and $r_q$.
    \end{itemize}
    \item Improving the time complexity of computation on $Z_{r_q}$ is more tricky. Since $r_q$ is completely random and $Z_{r_q}$ needs to be evaluated on $P \times X$ points on the boolean hypercube, this does not give us much room to wiggle. The best solution (currently) is to evaluate $Q$ in reverse order, i.e. start from the least siginificant bit. This allows us to keep skipping invalid $p, q$ pairs since the most significant bits of $q$ are still within the boolean hypercube. The only problem is that once $q$ is reduced to 1, we can no longer cut the evaluation size by half. Overall, this reduces the time complexity of computing $Z_{r_q}$ to $O(\Qsum\cdot \log(P\cdot\Qmax) \cdot X)$.
\end{itemize}

\section{Reducing Space Complexity}\label{reduce-space}

Idea: express $Z$ as a polynomial over $p$ times a polynomial over $q$ over a polynomial over $x$

\end{document}